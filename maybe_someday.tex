\paragraph {Preprocessing}  According to the final application of the system, we deal with "irregularities" present within the text, so that we can extract more informative features from it. Conventional techniques include conflating (or blend) words according to their stems (stemming), conflating words with respect to their lemmas (lemmatization), removing functional words (articles, determinants, etc.), case normalization, replacing numeric tokens with strings, among others.

\paragraph {Feature Representation} In data analysis we often hear the saying "Garbage In, Garbage Out". Indeed, knowledge discovery (i.e., machine learning methods)  can only do so much with the input data they are given.  This step is then crucial for any NLP or data mining system.   During this step we transform each textual unit from the input corpus into a numerical representation (i.e., a matrix) that is compatible with the machine learning methods used in the following step.
%As we will see below, this dissertation focus on the challenges and opportunities this step presents. 

\paragraph {Knowledge Discovery} Several NLP tasks can be seen, directly or indirectly, as tasks assigning labels to words \cite{Collobert2011}. In that sense, machine learning methods are used to solve this kind of problems and thus are naturally used to solve most NLP problems nowadays. Either supervised learning (leveraging annotated corpora) or unsupervised learning (finding related elements within the text, without any extra information), the goal is always to find interesting insights from the input corpus, towards a general language understanding. 