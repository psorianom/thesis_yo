\documentclass[a4paper,11pt,twoside]{ThesisStyle}

\include{formatAndDefs}

\begin{document}

\include{TitlePage}
\chapter*{Abstract}
Making sense of textual data is an essential requirement in order to make computers understand our language. To extract actionable information from text, we need to represent it by means of descriptors before using knowledge discovery techniques. The goal of this thesis is to shed light into heterogeneous representations of words and how to leverage them  while addressing their implicit sparse nature.

First, we  propose a hypergraph network model that holds heterogeneous linguistic data in a single unified model. In other words, we introduce a model that represents words by means of different linguistic properties and links them together according to said properties. Our proposition differs to other types of linguistic networks in that we aim to provide a general structure that can hold several types of descriptive text features, instead of a single one as in most representations. This representation may be used to analyze the inherent properties of language from different points of view, or to be the departing point of an applied NLP task pipeline. Secondly, we employ feature fusion techniques to provide a final single enriched representation that exploits the heterogeneous nature of the model and alleviates the sparseness of each representation.

These types of techniques are regularly used exclusively to combine multimedia data. In our approach, we consider different text representations as distinct sources of information which can be enriched by themselves. This approach has not been explored before, to the best of our knowledge.
Thirdly, we propose an algorithm that exploits the characteristics of the network to identify and group semantically related words by exploiting the real-world properties of the networks. In contrast with similar methods that are also based on the structure of the network, our algorithm reduces the number of required parameters and more importantly, allows for the use of either lexical or syntactic networks to discover said groups of words, instead of the single type of features usually employed.

 We focus on two different natural language processing tasks: Word Sense Induction and Disambiguation (WSI/WSD), and Named Entity Recognition (NER). In total, we test our propositions on four different open-access datasets. The results obtained allow us to show the pertinence of our contributions and also give us some insights into the properties of heterogeneous features and their combinations with fusion methods. Specifically, our experiments are twofold: first, we show that using fusion-enriched heterogeneous features, coming from our proposed linguistic network, we outperform the performance of single features' systems and other basic baselines. We note that using single fusion operators is not efficient compared to using a combination of them in order to obtain a final space representation. We show that the features added by each combined fusion operation are important towards the models predicting the appropriate classes. We test the enriched representations on both WSI/WSD and NER tasks. Secondly, we address the WSI/WSD task with our network-based proposed method. While based on previous work, we improve it by obtaining better overall performance and reducing the number of parameters needed. We also discuss the use of either lexical or syntactic networks to solve the task. 

Finally, we parse a corpus based on the English Wikipedia and then store it following the proposed network model. The parsed Wikipedia version serves as a linguistic resource to be used by other researchers. Contrary to other similar resources, instead of just storing its part of speech tag and its dependency relations,  we also take into account the constituency-tree information of each word analyzed. The hope is for this resource to be used on future developments without the need to compile such resource from zero.

\paragraph{Keywords.} Natural Language Processing, Linguistic Network, Word Representation, Fusion Techniques, Word Sense Induction and Disambiguation, Named Entity Recognition
\newpage

\chapter*{Résumé}

Donner du sens aux données textuelles est une besoin essentielle pour faire les ordinateurs comprendre notre langage. Pour extraire des informations exploitables du texte, nous devons les représenter avec des descripteurs avant d'utiliser des techniques d'apprentissage. Dans ce sens, le but de cette thèse est de faire la lumière sur les représentations hétérogènes des mots et sur la façon de les exploiter tout en abordant leur nature implicitement éparse.

Dans un premier temps, nous proposons un modèle de réseau basé sur des hypergraphes qui contient des données linguistiques hétérogènes dans un seul modèle unifié. En d'autres termes, nous introduisons un modèle qui représente les mots au moyen de différentes propriétés linguistiques et les relie ensemble en fonction desdites propriétés. Notre proposition diffère des autres types de réseaux linguistiques parce que nous visons à fournir une structure générale pouvant contenir plusieurs types de caractéristiques descriptives du texte, au lieu d'une seule comme dans la plupart des représentations existantes. Cette représentation peut être utilisée pour analyser les propriétés inhérentes du langage à partir de différents points de vue, ou pour être le point de départ d'un pipeline de tâches du traitement automatique de langage. Deuxièmement, nous utilisons des techniques de fusion de caractéristiques pour fournir une représentation enrichie unique qui exploite la nature hétérogène du modèle et atténue l'eparsité de chaque représentation.
Ces types de techniques sont régulièrement utilisés exclusivement pour combiner des données multimédia. Dans notre approche, nous considérons différentes représentations de texte comme des sources d'information distinctes qui peuvent être enrichies par elles-mêmes. Cette approche n'a pas été explorée auparavant, à notre connaissance.
Troisièmement, nous proposons un algorithme qui exploite les caractéristiques du réseau pour identifier et grouper des mots liés sémantiquement en exploitant les propriétés  des réseaux. Contrairement aux méthodes similaires qui sont également basées sur la structure du réseau, notre algorithme réduit le nombre de paramètres requis et surtout, permet l'utilisation de réseaux lexicaux ou syntaxiques pour découvrir les groupes de mots, au lieu d'un type unique des caractéristiques comme elles sont habituellement employées.

Nous nous concentrons sur deux tâches différentes de traitement du langage naturel: l'induction et la induction et désambiguïsation des sens des mots (en anglais, Word Sense Induction and Disambiguation, ou WSI/WSD) et la reconnaissance d'entité nommées (en anglais, Named Entity Recognition, ou NER). Au total, nous testons nos propositions sur quatre ensembles de données différents. Nous effectuons nos expériences et développements en utilisant des corpus à accès libre. Les résultats obtenus nous permettent de montrer la pertinence de nos contributions et nous donnent également un aperçu des propriétés des caractéristiques hétérogènes et de leurs combinaisons avec les méthodes de fusion. Plus précisément, nos expériences sont doubles: premierment,  nous montrons qu'en utilisant des caractéristiques hétérogènes enrichies par la fusion, provenant de notre réseau linguistique proposé, nous surpassons la performance des systèmes à caractéristiques uniques et basés sur la simple concatenation de characteristiques. Aussi, nous analysons les opérateurs de fusion utilisés afin de mieux comprendre la raison de ces améliorations. En général, l'utilisation independante d'opérateurs de fusion  n'est pas aussi efficace que l'utilisation d'une combinaison de ceux-ci pour obtenir  une représentation spatiale finale. Nous testons sur les tâches WSI/WSD et NER mentionnées ci-dessus. Et deuxiement, nous abordons encore une fois la tâche WSI/WSD, cette fois-ci avec la méthode  à base de graphes proposée afin de démontrer sa pertinence par rapport à la tâche. Nous discutons les différents résultats obtenus avec des caractéristiques lexicales ou syntaxiques.

Enfin, nous analysons un corpus basé sur Wikipedia en anglais et le stockons en suivant le modèle de réseau proposé. La version Wikipédia analysée sert de ressource linguistique à utiliser par d'autres chercheurs. Contrairement à d'autres ressources similaires, au lieu de simplement stocker l'étiquette morpho-syntaxique et ses relations de dépendance, nous prenons également en compte les informations de l'arbre syntaxique de chaque mot analysé. L'idée est que cette ressource soit utilisée pour de futurs développements sans avoir besoin de compiler une telle ressource à partir de zéro.

\paragraph{Mots clés.} Traitement automatique du langage naturel, réseaux linguistiques, représentation de mots, techniques de fusion, reconnaissance d'entités nommées, induction et désambiguïsation du sens des mots. 

%\input{abstract.tex}
\dominitoc

\pagenumbering{roman}


 

\newpage
\chapter*{Acknowledgments}
A lot of time and effort from a lot of people has gone into this work. Without all these people, this document could not exist.

First of all, I would like to profoundly thank my supervisors, Sabine Loudcher and Julien Ah-Pine, whom  never quit on me during this endeavor. When I recall the surprises and unexpected events I came up with throughout these years, I am amazed at their patience and guidance through it all. Thank you sincerely.

I am very grateful with my jury members who accepted to review this work:  Marc El-Bèze, Mathieu Roche, Farah Benamara Zitoune and Sophie Rosset. Thank you for your time and understanding.

Thanks to my friends from the lab, Xinyu, Rado and Jairo, for being there and helping me to put things on perspective or to have some beers. Also thanks to the rest of the lab for having me there. 

Special recognition to my Mexican-Spanish friends, Viri, Humberto, Inma, Zaruhi, Mónica. All of you were there with me during the bad and good times, and for that I thank you. You are Lyon for me. Also to Claire, for having been part of all of this.


This thesis is the result of a lot of latent effort and love from my mother, father, sister and brother, which directly or indirectly, made, and continue to make, my living so far away manageable. 


Thank you all.

 
%
%Last thing to do :-)

\tableofcontents
\cleardoublepage

\listoftables

\listoffigures

\mainmatter
\input{Chapter1}
\input{Chapter2}
\input{Chapter3}
\input{Chapter4}
%\input{Chapter5}
\input{Conclusion}
%\appendix

%\include{Appendix1}

\bibliographystyle{ThesisStyle}
\bibliography{Thesis_f}

%\printnomenclature

\cleardoublepage

\end{document}
